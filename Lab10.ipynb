{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.compat.v1.estimator.inputs\n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('./faces_TM.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_persons = ['sz24', 'megak', 'night', 'choon', 'kawamura']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 469, Test size: 155\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "image_list = []\n",
    "for filepath in glob.glob('faces_TM/*/*.jpg', recursive=True):\n",
    "    filename = filepath.split(\"/\")[-1]\n",
    "    person = filepath.split(\"/\")[1]\n",
    "    label = filename.split(\"_\")[1]\n",
    "    test_train = person in test_persons\n",
    "    image_list.append((filepath, label, int(test_train)))\n",
    "    \n",
    "# Create a data frame\n",
    "data = pd.DataFrame(data=image_list, columns=['image_path', 'label', 'isTest'])\n",
    "\n",
    "# Convert string labels to numeric\n",
    "d = {'left':0, 'right':1, 'straight':2, 'up':3}\n",
    "data['labels_num'] = data['label'].map(d, na_action='ignore')\n",
    "\n",
    "# Generate two data frames for training and validation\n",
    "train_df = data[data['isTest']==0]\n",
    "validation_df = data[data['isTest']==1]\n",
    "print('Train size: {}, Test size: {}'.format(train_df.shape[0], validation_df.shape[0] ) )\n",
    "N_train_images = train_df.shape[0]\n",
    "N_val_images = validation_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Input, Lambda\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "\n",
    "# Input layer\n",
    "input_ = Input(shape=(28, 28, 3)) # This is the input shape\n",
    "# Keras data loader does not like to read 1 channel images. This Lambda finction removes the extra channels added by data loader.\n",
    "input_slice = Lambda(lambda x: tf.expand_dims(x[:,:,:,0], -1, name=None))(input_)\n",
    "x = Flatten()(input_slice) # This will convert the 28x28 input to a vector of dimension 784\n",
    "\n",
    "# Hidden layer\n",
    "h = Dense(64)(x)\n",
    "h = Activation('sigmoid')(h)\n",
    "\n",
    "# Output layer\n",
    "out_ = Dense(4)(h)\n",
    "out_ = Activation('softmax')(out_)\n",
    "model = Model(inputs=input_, outputs=out_) # Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=sgd,\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 28, 28, 3)]       0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 50,500\n",
      "Trainable params: 50,500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 469 validated image filenames belonging to 4 classes.\n",
      "Found 155 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "batch_size = 16\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory='./',\n",
    "        x_col=\"image_path\",\n",
    "        y_col=\"label\",\n",
    "        target_size=(28, 28),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=validation_df,\n",
    "        directory='./',\n",
    "        x_col=\"image_path\",\n",
    "        y_col=\"label\",\n",
    "        target_size=(28, 28),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_losses(model_, data_generator_, N_images, batch_size_):\n",
    "    loss_hold = []\n",
    "    acc_hold = []\n",
    "    batches = 0\n",
    "    for x,y in data_generator_:\n",
    "        loss,acc = model_.evaluate(x, y, verbose=0)\n",
    "        loss_hold.append(loss)\n",
    "        acc_hold.append(acc)\n",
    "        batches += 1\n",
    "        if batches >= N_images / batch_size_:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "    return np.mean(loss_hold), np.mean(acc_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "Training epoch 0: Loss = 1.3950610160827637, Accuracy = 0.2929166853427887\n",
      "Validation epoch 0: Loss = 1.2879704356193542, Accuracy = 0.42045456171035767\n",
      "Epoch 1\n",
      "Training epoch 1: Loss = 1.215722918510437, Accuracy = 0.6002469658851624\n",
      "Validation epoch 1: Loss = 1.0837776899337768, Accuracy = 0.6789773106575012\n",
      "Epoch 2\n",
      "Training epoch 2: Loss = 1.0805022716522217, Accuracy = 0.6551080942153931\n",
      "Validation epoch 2: Loss = 0.9433213829994201, Accuracy = 0.6119318008422852\n",
      "Epoch 3\n",
      "Training epoch 3: Loss = 0.9577205777168274, Accuracy = 0.7056789994239807\n",
      "Validation epoch 3: Loss = 0.8281258940696716, Accuracy = 0.7630681991577148\n",
      "Epoch 4\n",
      "Training epoch 4: Loss = 0.8503329157829285, Accuracy = 0.7701080441474915\n",
      "Validation epoch 4: Loss = 0.7202162265777587, Accuracy = 0.7602273225784302\n",
      "Epoch 5\n",
      "Training epoch 5: Loss = 0.7601014971733093, Accuracy = 0.7772067785263062\n",
      "Validation epoch 5: Loss = 0.6719814896583557, Accuracy = 0.8596590757369995\n",
      "Epoch 6\n",
      "Training epoch 6: Loss = 0.6996574401855469, Accuracy = 0.7942284345626831\n",
      "Validation epoch 6: Loss = 0.6026619493961334, Accuracy = 0.8505681753158569\n",
      "Epoch 7\n",
      "Training epoch 7: Loss = 0.6238204836845398, Accuracy = 0.8596605062484741\n",
      "Validation epoch 7: Loss = 0.544009679555893, Accuracy = 0.8596590757369995\n",
      "Epoch 8\n",
      "Training epoch 8: Loss = 0.5498584508895874, Accuracy = 0.8721450567245483\n",
      "Validation epoch 8: Loss = 0.5078921645879746, Accuracy = 0.8596590757369995\n",
      "Epoch 9\n",
      "Training epoch 9: Loss = 0.49746084213256836, Accuracy = 0.8975308537483215\n",
      "Validation epoch 9: Loss = 0.49704970717430114, Accuracy = 0.8318182229995728\n",
      "Epoch 10\n",
      "Training epoch 10: Loss = 0.46920445561408997, Accuracy = 0.8904783725738525\n",
      "Validation epoch 10: Loss = 0.4603123962879181, Accuracy = 0.8659090995788574\n",
      "Epoch 11\n",
      "Training epoch 11: Loss = 0.4218389391899109, Accuracy = 0.9204475283622742\n",
      "Validation epoch 11: Loss = 0.45514333695173265, Accuracy = 0.8471590876579285\n",
      "Epoch 12\n",
      "Training epoch 12: Loss = 0.39368587732315063, Accuracy = 0.9137808680534363\n",
      "Validation epoch 12: Loss = 0.4644967257976532, Accuracy = 0.8443182110786438\n",
      "Epoch 13\n",
      "Training epoch 13: Loss = 0.37016919255256653, Accuracy = 0.9254629611968994\n",
      "Validation epoch 13: Loss = 0.4549993425607681, Accuracy = 0.8227273225784302\n",
      "Epoch 14\n",
      "Training epoch 14: Loss = 0.3454420268535614, Accuracy = 0.9238117337226868\n",
      "Validation epoch 14: Loss = 0.42433551102876665, Accuracy = 0.8687499761581421\n",
      "Epoch 15\n",
      "Training epoch 15: Loss = 0.3184259533882141, Accuracy = 0.9270833134651184\n",
      "Validation epoch 15: Loss = 0.4906798660755157, Accuracy = 0.8096591234207153\n",
      "Epoch 16\n",
      "Training epoch 16: Loss = 0.3035101294517517, Accuracy = 0.9346450567245483\n",
      "Validation epoch 16: Loss = 0.44678260684013366, Accuracy = 0.8414772748947144\n",
      "Epoch 17\n",
      "Training epoch 17: Loss = 0.2910841107368469, Accuracy = 0.9292438626289368\n",
      "Validation epoch 17: Loss = 0.4563503533601761, Accuracy = 0.84375\n",
      "Epoch 18\n",
      "Training epoch 18: Loss = 0.28733232617378235, Accuracy = 0.9354166388511658\n",
      "Validation epoch 18: Loss = 0.4819979637861252, Accuracy = 0.8295454978942871\n",
      "Epoch 19\n",
      "Training epoch 19: Loss = 0.2623310685157776, Accuracy = 0.9334105253219604\n",
      "Validation epoch 19: Loss = 0.4561344772577286, Accuracy = 0.8221591114997864\n",
      "Epoch 20\n",
      "Training epoch 20: Loss = 0.2576350271701813, Accuracy = 0.9496142268180847\n",
      "Validation epoch 20: Loss = 0.4718509495258331, Accuracy = 0.8164772987365723\n",
      "Epoch 21\n",
      "Training epoch 21: Loss = 0.24636530876159668, Accuracy = 0.9450617432594299\n",
      "Validation epoch 21: Loss = 0.47304114401340486, Accuracy = 0.8289772868156433\n",
      "Epoch 22\n",
      "Training epoch 22: Loss = 0.2450707107782364, Accuracy = 0.9329938292503357\n",
      "Validation epoch 22: Loss = 0.4596322953701019, Accuracy = 0.8255681991577148\n",
      "Epoch 23\n",
      "Training epoch 23: Loss = 0.2389083206653595, Accuracy = 0.9387808442115784\n",
      "Validation epoch 23: Loss = 0.48612339943647387, Accuracy = 0.8346590995788574\n",
      "Epoch 24\n",
      "Training epoch 24: Loss = 0.23173299431800842, Accuracy = 0.9496142268180847\n",
      "Validation epoch 24: Loss = 0.5061078667640686, Accuracy = 0.8005682229995728\n",
      "Epoch 25\n",
      "Training epoch 25: Loss = 0.23625709116458893, Accuracy = 0.9379784464836121\n",
      "Validation epoch 25: Loss = 0.48066352754831315, Accuracy = 0.8284090757369995\n",
      "Epoch 26\n",
      "Training epoch 26: Loss = 0.21727174520492554, Accuracy = 0.957561731338501\n",
      "Validation epoch 26: Loss = 0.48336518108844756, Accuracy = 0.8289772868156433\n",
      "Epoch 27\n",
      "Training epoch 27: Loss = 0.20786137878894806, Accuracy = 0.9425617456436157\n",
      "Validation epoch 27: Loss = 0.5014736920595169, Accuracy = 0.8068181872367859\n",
      "Epoch 28\n",
      "Training epoch 28: Loss = 0.20161326229572296, Accuracy = 0.9496142268180847\n",
      "Validation epoch 28: Loss = 0.4405315272510052, Accuracy = 0.8500000238418579\n",
      "Epoch 29\n",
      "Training epoch 29: Loss = 0.19486311078071594, Accuracy = 0.956250011920929\n",
      "Validation epoch 29: Loss = 0.47701909840106965, Accuracy = 0.8352273106575012\n",
      "Epoch 30\n",
      "Training epoch 30: Loss = 0.1932879239320755, Accuracy = 0.9421296715736389\n",
      "Validation epoch 30: Loss = 0.4984749212861061, Accuracy = 0.8198863863945007\n",
      "Epoch 31\n",
      "Training epoch 31: Loss = 0.19281059503555298, Accuracy = 0.9513117671012878\n",
      "Validation epoch 31: Loss = 0.5173733606934547, Accuracy = 0.8005682229995728\n",
      "Epoch 32\n",
      "Training epoch 32: Loss = 0.1791103035211563, Accuracy = 0.9579475522041321\n",
      "Validation epoch 32: Loss = 0.49733146503567693, Accuracy = 0.8346590995788574\n",
      "Epoch 33\n",
      "Training epoch 33: Loss = 0.1870841383934021, Accuracy = 0.9533641934394836\n",
      "Validation epoch 33: Loss = 0.5141336172819138, Accuracy = 0.8102272748947144\n",
      "Epoch 34\n",
      "Training epoch 34: Loss = 0.17506766319274902, Accuracy = 0.9596450924873352\n",
      "Validation epoch 34: Loss = 0.5181482516229152, Accuracy = 0.8193181753158569\n",
      "Epoch 35\n",
      "Training epoch 35: Loss = 0.171475350856781, Accuracy = 0.9562962651252747\n",
      "Validation epoch 35: Loss = 0.49994026273489, Accuracy = 0.8136364221572876\n",
      "Epoch 36\n",
      "Training epoch 36: Loss = 0.17097894847393036, Accuracy = 0.9508950710296631\n",
      "Validation epoch 36: Loss = 0.5399698942899704, Accuracy = 0.8193181753158569\n",
      "Epoch 37\n",
      "Training epoch 37: Loss = 0.17152298986911774, Accuracy = 0.9600308537483215\n",
      "Validation epoch 37: Loss = 0.5022200033068657, Accuracy = 0.8193181753158569\n",
      "Epoch 38\n",
      "Training epoch 38: Loss = 0.1826467216014862, Accuracy = 0.9637808203697205\n",
      "Validation epoch 38: Loss = 0.4741100862622261, Accuracy = 0.84375\n",
      "Epoch 39\n",
      "Training epoch 39: Loss = 0.15170380473136902, Accuracy = 0.9675154089927673\n",
      "Validation epoch 39: Loss = 0.5089304573833943, Accuracy = 0.8193181753158569\n",
      "Epoch 40\n",
      "Training epoch 40: Loss = 0.15101628005504608, Accuracy = 0.9641975164413452\n",
      "Validation epoch 40: Loss = 0.5085073336958885, Accuracy = 0.8227273225784302\n",
      "Epoch 41\n",
      "Training epoch 41: Loss = 0.14594446122646332, Accuracy = 0.9625462889671326\n",
      "Validation epoch 41: Loss = 0.5148870319128036, Accuracy = 0.8289772868156433\n",
      "Epoch 42\n",
      "Training epoch 42: Loss = 0.1516413390636444, Accuracy = 0.9679784178733826\n",
      "Validation epoch 42: Loss = 0.5375127792358398, Accuracy = 0.8130682110786438\n",
      "Epoch 43\n",
      "Training epoch 43: Loss = 0.14423450827598572, Accuracy = 0.9712963104248047\n",
      "Validation epoch 43: Loss = 0.5124154280871153, Accuracy = 0.8187500238418579\n",
      "Epoch 44\n",
      "Training epoch 44: Loss = 0.13793423771858215, Accuracy = 0.9708333611488342\n",
      "Validation epoch 44: Loss = 0.5107819952070713, Accuracy = 0.8318182229995728\n",
      "Epoch 45\n",
      "Training epoch 45: Loss = 0.1331518441438675, Accuracy = 0.9683641791343689\n",
      "Validation epoch 45: Loss = 0.5400014787912368, Accuracy = 0.8193181753158569\n",
      "Epoch 46\n",
      "Training epoch 46: Loss = 0.13591201603412628, Accuracy = 0.9721450805664062\n",
      "Validation epoch 46: Loss = 0.5200256958603859, Accuracy = 0.8221591114997864\n",
      "Epoch 47\n",
      "Training epoch 47: Loss = 0.1275850236415863, Accuracy = 0.9675154089927673\n",
      "Validation epoch 47: Loss = 0.5188132256269455, Accuracy = 0.824999988079071\n",
      "Epoch 48\n",
      "Training epoch 48: Loss = 0.123870350420475, Accuracy = 0.9750000238418579\n",
      "Validation epoch 48: Loss = 0.4932024657726288, Accuracy = 0.824999988079071\n",
      "Epoch 49\n",
      "Training epoch 49: Loss = 0.1206694170832634, Accuracy = 0.9750000238418579\n",
      "Validation epoch 49: Loss = 0.5256572067737579, Accuracy = 0.8221591114997864\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for e in range(50): # Train for 50 epoch\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    \n",
    "    loss_ = []\n",
    "    acc_ = []\n",
    "    \n",
    "    # iterate over each batch\n",
    "    for x,y in train_generator:\n",
    "        loss, acc = model.train_on_batch(x, y)\n",
    "        loss_.append(loss)\n",
    "        acc_.append(acc)\n",
    "        batches += 1\n",
    "        if batches >= N_train_images / batch_size:\n",
    "            break\n",
    "    loss_ = np.mean(loss_)\n",
    "    acc_ = np.mean(acc_)\n",
    "    print(\"Training epoch {}: Loss = {}, Accuracy = {}\".format(e, loss_, acc_))\n",
    "    \n",
    "    loss, acc = calculate_losses(model, validation_generator, N_val_images, batch_size)\n",
    "    print(\"Validation epoch {}: Loss = {}, Accuracy = {}\".format(e, loss, acc))\n",
    "    \n",
    "    res.append((e, loss_, acc_, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
